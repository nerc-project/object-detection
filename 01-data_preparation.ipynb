{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "801a18ed-61d2-4e11-abc3-1ad9bac55cef",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791894f3-1b26-4ac0-9b19-7d91eaca70b9",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c85bb-aad4-4b04-8f62-bf6e80bc27a6",
   "metadata": {},
   "source": [
    "### We will start by installing the library to download the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a86fdf6-a2d8-4f64-b273-9e8d218ac700",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -q openimages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84073a89-a4af-41c1-8ae5-10468d21a8aa",
   "metadata": {},
   "source": [
    "### We must also make sure we have the right version of opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c45f7-0083-49a8-aefb-f9a5a20d5c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -qy opencv-python\n",
    "!pip install -q opencv-python-headless #version meant to be used in a containerized environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a63a75-84f6-4aea-b12b-a2fe0ab1427b",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will now download the dataset for 3 classes: Bicyle, Car, and Trafic sign. We are only downloading 300 images per class to limit the processing time in this example. However, to achieve a robust YOLOv5 model, it is recommended to train with over 1500 images per class, and more then 10,000 instances per class.\n",
    "\n",
    "We specify the darknet format (â€“format darknet), which is the format YOLO can handle. This will create folders for each class, in which we will have darknet and images folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f0e6c-b6b5-4692-898d-613b40e93f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = 'Bicycle Car \"Traffic sign\"'\n",
    "limit = 300\n",
    "!oi_download_dataset --base_dir download --csv_dir download --labels {labels} --format darknet --limit {limit}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10741c2-a15a-41dd-b5d9-79e53b7ed52b",
   "metadata": {},
   "source": [
    "### Let's have a look at a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8307836-4d7a-481b-8126-d88f7eedc5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def show_bbox(image_path):\n",
    "    # convert image path to label path\n",
    "    label_path = image_path.replace('/images/', '/darknet/')\n",
    "    label_path = label_path.replace('.jpg', '.txt')\n",
    "\n",
    "    # Open the image and create ImageDraw object for drawing\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            # Split the line into five values\n",
    "            label, x, y, w, h = line.split(' ')\n",
    "\n",
    "            # Convert string into float\n",
    "            x = float(x)\n",
    "            y = float(y)\n",
    "            w = float(w)\n",
    "            h = float(h)\n",
    "\n",
    "            # Convert center position, width, height into\n",
    "            # top-left and bottom-right coordinates\n",
    "            W, H = image.size\n",
    "            x1 = (x - w/2) * W\n",
    "            y1 = (y - h/2) * H\n",
    "            x2 = (x + w/2) * W\n",
    "            y2 = (y + h/2) * H\n",
    "\n",
    "            # Draw the bounding box with red lines\n",
    "            draw.rectangle((x1, y1, x2, y2),\n",
    "                           outline=(255, 0, 0), # Red in RGB\n",
    "                           width=5)             # Line width\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d943f-f47c-409d-8eb8-c7f6a37a6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('download/car/images')\n",
    "random_file = random.choice(files)\n",
    "show_bbox('download/car/images/' + random_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86bbe9a-9374-4538-a212-1cd48d963fb2",
   "metadata": {},
   "source": [
    "### Now, let's prepare our training data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afd27d2-619b-4c0e-8733-2b9484d94e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder structure for YOLOv5 training\n",
    "if not os.path.exists('data'):\n",
    "    for folder in ['images', 'labels']:\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            os.makedirs(f'data/{folder}/{split}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e81451-cc23-4924-ad52-26e98ac7bd54",
   "metadata": {},
   "source": [
    "### As all images will end up in the same folder, we must check for duplicate images (an image can contain multiple classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045364be-3bdb-48a6-834d-28c202dd24c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def get_filenames(folder):\n",
    "    filenames = set()\n",
    "\n",
    "    for path in glob.glob(os.path.join(folder, '*.jpg')):\n",
    "        # Extract the filename\n",
    "        filename = os.path.split(path)[-1]\n",
    "        filenames.add(filename)\n",
    "\n",
    "    return filenames\n",
    "\n",
    "\n",
    "# classes filename sets\n",
    "bicycle_images = get_filenames('download/bicycle/images')\n",
    "car_images = get_filenames('download/car/images')\n",
    "traffic_sign_images = get_filenames('download/traffic sign/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb685de-8711-4e8b-86dd-b19420222b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates1 = bicycle_images & car_images\n",
    "duplicates2 = car_images & traffic_sign_images\n",
    "duplicates3 = traffic_sign_images & bicycle_images\n",
    "\n",
    "print(duplicates1)\n",
    "print(duplicates2)\n",
    "print(duplicates3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1202de3-1d10-44b2-a2f9-829e246f74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup duplicates\n",
    "bicycle_images -= duplicates1\n",
    "car_images -= duplicates2\n",
    "traffic_sign_images -= duplicates3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f88f45d-27ec-4ab7-9797-47625747bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new datasets sizes\n",
    "print(len(bicycle_images))\n",
    "print(len(car_images))\n",
    "print(len(traffic_sign_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b1fdf-b0d3-428e-b88a-1f6768b659dc",
   "metadata": {},
   "source": [
    "### We can now randomly split all our images in train/val/test\n",
    "\n",
    "We will use here a standard split scheme: 0.75, 0.125, 0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260332de-cf25-4770-ba3b-4467311df573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "bicycle_images = np.array(list(bicycle_images))\n",
    "car_images = np.array(list(car_images))\n",
    "traffic_sign_images = np.array(list(traffic_sign_images))\n",
    "\n",
    "# Use the same random seed for reproducability\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(bicycle_images)\n",
    "np.random.shuffle(car_images)\n",
    "np.random.shuffle(traffic_sign_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d52625-80ff-4be7-bce7-2d86af513a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import math\n",
    "\n",
    "\n",
    "def split_dataset(item, image_names, train_size, val_size):\n",
    "    for i, image_name in enumerate(image_names):\n",
    "        # Label filename\n",
    "        label_name = image_name.replace('.jpg', '.txt')\n",
    "\n",
    "        # Split into train, val, or test\n",
    "        if i < train_size:\n",
    "            split = 'train'\n",
    "        elif i < train_size + val_size:\n",
    "            split = 'val'\n",
    "        else:\n",
    "            split = 'test'\n",
    "\n",
    "        # Source paths\n",
    "        source_image_path = f'download/{item}/images/{image_name}'\n",
    "        source_label_path = f'download/{item}/darknet/{label_name}'\n",
    "\n",
    "        # Destination paths\n",
    "        target_image_folder = f'data/images/{split}'\n",
    "        target_label_folder = f'data/labels/{split}'\n",
    "\n",
    "        # Copy files\n",
    "        shutil.copy(source_image_path, target_image_folder)\n",
    "        shutil.copy(source_label_path, target_label_folder)\n",
    "\n",
    "\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.125\n",
    "\n",
    "# Bicycle data\n",
    "bicycle_train_size = math.floor(train_ratio * len(bicycle_images))\n",
    "bicycle_val_size = math.floor(val_ratio * len(bicycle_images))\n",
    "split_dataset('bicycle', bicycle_images, train_size=bicycle_train_size, val_size=bicycle_val_size)\n",
    "\n",
    "# Car data\n",
    "car_train_size = math.floor(train_ratio * len(car_images))\n",
    "car_val_size = math.floor(val_ratio * len(car_images))\n",
    "split_dataset('car', car_images, train_size=car_train_size, val_size=car_val_size)\n",
    "\n",
    "# Traffic sign data\n",
    "traffic_sign_train_size = math.floor(train_ratio * len(traffic_sign_images))\n",
    "traffic_sign_val_size = math.floor(val_ratio * len(traffic_sign_images))\n",
    "split_dataset('traffic sign', traffic_sign_images, train_size=traffic_sign_train_size, val_size=traffic_sign_val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8fe7f0-5dc8-44c9-acd9-1d8b5b633aa7",
   "metadata": {},
   "source": [
    "### Our dataset is now ready to use for training!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
